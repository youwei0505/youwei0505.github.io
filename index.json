[{"authors":["admin"],"categories":null,"content":"My name is Chih-Ting Liu (劉致廷 in Chinese). I am a Computer Vision Applied Scientist in Amazon Lab126 at Taipei, Taiwan. I work on enabling cutting-edge computer vision features on Amazon devices and Ring devices. In July 2022, I received my Ph.D. degree from National Taiwan University (NTU) at the Media IC and System Lab, advised by Prof. Shao-Yi Chien.\nMy research interest is mainly on recongnition system in computer vision, including human recognition (re-identification), face recognition and object tracking. Moreover, in order to deploy AI on edge devices, I also focus on techniques related to on-device training, such as federated learning, and on-device inference, such as network pruning. Here are my Google Scholar and CV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jackie840129.github.io/author/chih-ting-jackie-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chih-ting-jackie-liu/","section":"authors","summary":"My name is Chih-Ting Liu (劉致廷 in Chinese). I am a Computer Vision Applied Scientist in Amazon Lab126 at Taipei, Taiwan. I work on enabling cutting-edge computer vision features on Amazon devices and Ring devices.","tags":null,"title":"Chih-Ting (Jackie) Liu","type":"authors"},{"authors":["**chih-ting liu**","chien-yi wang","shao-yi chien","shang-hong lai"],"categories":["fl"],"content":"","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"7bc2e7b6316d0d9fc7c89feab5f4e5d8","permalink":"https://jackie840129.github.io/publication/aaai_2022/","publishdate":"2022-02-28T00:00:00Z","relpermalink":"/publication/aaai_2022/","section":"publication","summary":"Current state-of-the-art deep learning based face recognition (FR) models require a large number of face identities for central training. However, due to the growing privacy awareness, it is prohibited to access the face images on user devices to continually improve face recognition models. Federated Learning (FL) is a technique to address the privacy issue, which can collaboratively optimize the model without sharing the data between clients. In this work, we propose a FL based framework called FedFR to improve the generic face representation in a privacy-aware manner. Besides, the framework jointly optimizes personalized models for the corresponding clients via the proposed Decoupled Feature Customization module. The client-specific personalized model can serve the need of optimized face recognition experience for registered identities at the local device. To the best of our knowledge, we are the first to explore the personalized face recognition in FL setup. The proposed framework is validated to be superior to previous approaches on several generic and personalized face recognition benchmarks with diverse FL scenarios. The source codes and our proposed personalized FR benchmark under FL setup are available at https://github.com/jackie840129/FedFR.","tags":["face recognition","federated learning"],"title":"FedFR: Joint Optimization Federated Framework for Generic and Personalized Face Recognition","type":"publication"},{"authors":["**chih-ting liu**","man-yu lee","tsai-shien chen","shao-yi chien"],"categories":["re-id"],"content":"","date":1632268800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632268800,"objectID":"c8e84e011189bd4c707514dde5e2039e","permalink":"https://jackie840129.github.io/publication/icip21_hsr/","publishdate":"2021-10-14T00:00:00Z","relpermalink":"/publication/icip21_hsr/","section":"publication","summary":"Person re-identification (re-ID) has received great success with the supervised learning methods. However, the task of unsupervised cross-domain re-ID is still challenging. In this paper, we propose a Hard Samples Rectification (HSR) learning scheme which resolves the weakness of original clustering-based methods being vulnerable to the hard positive and negative samples in the target unlabelled dataset. Our HSR contains two parts, an inter-camera mining method that helps recognize a person under different views (hard positive) and a part-based homogeneity technique that makes the model discriminate different persons but with similar appearance (hard negative). By rectifying those two hard cases, the re-ID model can learn effectively and achieve promising results on two large-scale benchmarks.","tags":["person re-identification","unsupervised re-id"],"title":"Hard Samples Rectification for Unsupervised Cross-domain Person Re-identification","type":"publication"},{"authors":["**chih-ting liu**","jun-cheng chen","chu-song chen","shao-yi chien"],"categories":["re-id"],"content":"","date":1623715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623715200,"objectID":"72c426545db84a882b4957ecd7c8b556","permalink":"https://jackie840129.github.io/publication/cvprw21_cfaan/","publishdate":"2020-10-14T00:00:00Z","relpermalink":"/publication/cvprw21_cfaan/","section":"publication","summary":"Video-based person re-identification (Re-ID) aims at matching the video tracklets with cropped video frames for identifying the pedestrians under different cameras. However, there exists severe spatial and temporal misalignment for those cropped tracklets due to the imperfect detection and tracking results generated with obsolete methods. To address this issue, we present a simple re-Detect and Link (DL) module which can effectively reduce those unexpected noise through applying the deep learning-based detection and tracking on the cropped tracklets. Furthermore, we introduce an improved model called Coarse-to-Fine AxialAttention Network (CF-AAN). Based on the typical Nonlocal Network, we replace the non-local module with three 1-D position-sensitive axial attentions, in addition to our proposed coarse-to-fine structure. With the developed CFAAN, compared to the original non-local operation, we can not only significantly reduce the computation cost but also obtain the state-of-the-art performance (91.3% in rank1 and 86.5% in mAP) on the large-scale MARS dataset. Meanwhile, by simply adopting our DL module for data alignment, to our surprise, several baseline models can achieve better or comparable results with the current stateof-the-arts. Besides, we discover the errors not only for the identity labels of tracklets but also for the evaluation protocol for the test data of MARS. We hope that our work can help the community for the further development of invariant representation without the hassle of the spatial and temporal alignment and dataset noise. The code, corrected labels, evaluation protocol, and the aligned data will be available at https://github.com/jackie840129/CF-AAN","tags":["video-based re-identification","non-local attention"],"title":"Video-based Person Re-identification without Bells and Whistles","type":"publication"},{"authors":["chih-wei wu","**chih-ting liu**","[wei-chih tu](https://sites.google.com/site/wctu1009/)","yu tsao","[yu-chiang frank wang](https://www.ee.ntu.edu.tw/profile1.php?teacher_id=24037)","shao-yi chien"],"categories":["re-id"],"content":"","date":1602720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602720000,"objectID":"c4cd22ae90405100033d4b9c56b3109f","permalink":"https://jackie840129.github.io/publication/icip20_stgal/","publishdate":"2020-10-15T00:00:00Z","relpermalink":"/publication/icip20_stgal/","section":"publication","summary":"Person re-identification (Re-ID) aims to match images of the same person across distinct camera views. In this paper, we propose the Space-Time Guided Association Learning (STGAL) for unsupervised Re-ID without ground truth identity nor image correspondence observed during training. By exploiting the spatial-temporal information presented in pedestrian data, our STGAL is able to identify positive and negative image pairs for learning Re-ID feature representations. Experiments on a variety of datasets confirm the effectiveness of our approach, which achieves promising performance when comparing to the state-of-the-art methods.","tags":["person re-identification","space-time guided"],"title":"Space-Time Guided Association Learning For Unsupervised Person Re-Identification","type":"publication"},{"authors":["[tsai-shien chen](https://tsaishien-chen.github.io/)","**chih-ting liu**","chih-wei wu","shao-yi chien"],"categories":["re-id"],"content":"","date":1598227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598227200,"objectID":"577601a883d1ab64b38db2876294e378","permalink":"https://jackie840129.github.io/publication/eccv20_span/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/publication/eccv20_span/","section":"publication","summary":"Vehicle re-identification (re-ID) focuses on matching images of the same vehicle across different cameras. It is fundamentally challenging because differences between vehicles are sometimes subtle. While several studies incorporate spatial-attention mechanisms to help vehicle re-ID, they often require expensive keypoint labels or suffer from noisy attention mask if not trained with expensive labels. In this work, we propose a dedicated Semantics-guided Part Attention Network (SPAN) to robustly predict part attention masks for different views of vehicles given only image-level semantic labels during training. With the help of part attention masks, we can extract discriminative features in each part separately. Then we introduce Co-occurrence Part-attentive Distance Metric (CPDM) which places greater emphasis on co-occurrence vehicle parts when evaluating the feature distance of two images. Extensive experiments validate the effectiveness of the proposed method and show that our framework outperforms the state-of-the-art approaches.","tags":["vehicle re-identification","visibility-aware features","semantic-guided learning"],"title":"Orientation-aware Vehicle Re-identification with Semantics-guided Part Attention Network","type":"publication"},{"authors":["yu-cheng wu","**chih-ting liu**","bo-ying chen","shao-yi chien"],"categories":["pruning"],"content":"","date":1592006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592006400,"objectID":"b770d703ad7b5bdbf3417440ab303961","permalink":"https://jackie840129.github.io/publication/cvprw20_caie/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/publication/cvprw20_caie/","section":"publication","summary":"Filter pruning is an efficient way to structurally remove the redundant parameters in convolutional neural network, where at the same time reduces the computation, memory storage and transfer cost. Recent state-of-the-art methods globally estimate the importance of each filter based on its impact to the loss and iteratively remove those with smaller values until the pruned network meets some resource constraints, such as the commonly used number (or ratio) of filter left. However, when there is a more practical constraint like the total number of FLOPs, they ignore its relation to the estimation of filter importance. We propose a novel method called Constraint-Aware Importance Estimation (CAIE) that integrates information of the impact on the given resource into the original importance estimation only based on loss when pruning each filter. Moreover, our CAIE can be generalized to the pruning problem under multiple resource constraints simultaneously. Extensive experiments show that under the same multiple resource constraints, the model pruned with our CAIE method can not only accurately meet the constraints but also achieve the optimal performance results when comparing to existing state-of-the-art methods.","tags":["importance estimation","multiple resource constriants","filter pruning"],"title":"Constraint-Aware Importance Estimation for Global Filter Pruning Under Multiple Resource Constraints","type":"publication"},{"authors":["**chih-ting liu**","chih-wei wu","yu-chiang frank wang","shao-yi chien"],"categories":["re-id"],"content":"","date":1569110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569110400,"objectID":"fb3ab0705524c507f0a545c6b98fa2ae","permalink":"https://jackie840129.github.io/publication/bmvc19_stenvan/","publishdate":"2020-10-14T00:00:00Z","relpermalink":"/publication/bmvc19_stenvan/","section":"publication","summary":"Video-based person re-identification (Re-ID) aims at matching video sequences of pedestrians across non-overlapping cameras. It is a practical yet challenging task of how to embed spatial and temporal information of a video into its feature representation. While most existing methods learn the video characteristics by aggregating image-wise features and designing attention mechanisms in Neural Networks, they only explore the correlation between frames at high-level features. In this work, we target at refining the intermediate features as well as high-level features with non-local attention operations and make two contributions.(i) We propose a Non-local Video Attention Network (NVAN) to incorporate video characteristics into the representation at multiple feature levels.(ii) We further introduce a Spatially and Temporally Efficient Non-local Video Attention Network (STE-NVAN) to reduce the computation complexity by exploring spatial and temporal redundancy presented in pedestrian videos. Extensive experiments show that our NVAN outperforms state-of-the-arts by 3.8% in rank-1 accuracy on MARS dataset and confirms our STE-NVAN displays a much superior computation footprint compared to existing methods.","tags":["video-based re-identification","non-local attention"],"title":"Spatially and Temporally Efficient Non-local Attention Network for Video-based Person Re-Identification","type":"publication"},{"authors":["**chih-ting liu**","man-yu lee","chih-wei wu","bo-ying chen","tsai-shien chen","yao-ting hsu","shao-yi chien"],"categories":["re-id"],"content":"","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560988800,"objectID":"95e6804b54a20c97445845379dcfb0cd","permalink":"https://jackie840129.github.io/publication/cvprw19_jdrn/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/publication/cvprw19_jdrn/","section":"publication","summary":"in conjunction with 2019 NVIDIA AI City Challenge","tags":["vehicle re-identification","joint domain learning"],"title":"Supervised Joint Domain Learning for Vehicle Re-Identification","type":"publication"},{"authors":["**chih-ting liu**","tung-wei lin","yi-heng wu","yu-sheng lin","heng lee","yu tsao","shao-yi chien"],"categories":["pruning"],"content":"","date":1545868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545868800,"objectID":"e7c3ee3b4957cefcd072db2f78299ebd","permalink":"https://jackie840129.github.io/publication/tcas18_cpo/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/publication/tcas18_cpo/","section":"publication","summary":"Convolutional neural networks (CNNs) are widely employed in modern computer vision algorithms, where the input image is convolved iteratively by many filters to extract the knowledge behind it. However, while the depth of convolutional layers gets deeper and deeper in recent years, the enormous computational complexity makes it difficult to be deployed on embedded systems with limited hardware resources. In this paper, inspired by rate-distortion optimization in image and video coding, we propose a computation-performance optimization (CPO) method to remove the redundant convolution filters in a CNN with performance constraints. To prove the effectiveness of the proposed method, CPO is applied to the networks for image super-resolution and image classification. Under almost the same PSNR drop and accuracy drop for performance evaluation in these two tasks, we can achieve the best parameter and computation reduction when compared with previous works.","tags":["filter pruning","sensitivity"],"title":"Computation-Performance Optimization of Convolutional Neural Networks with Redundant Filter Removal","type":"publication"},{"authors":["chih-wei wu","**chih-ting liu**","cheng-en chiang","wei-chih tu","shao-yi chien"],"categories":["re-id"],"content":"","date":1529452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529452800,"objectID":"5ba36834921a27928215bf56a1b3e735","permalink":"https://jackie840129.github.io/publication/cvprw18_stp/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/publication/cvprw18_stp/","section":"publication","summary":"Vehicle re-identification (Re-ID) is fundamentally challenging due to the difficulties in data labeling, visual domain mismatch between datasets and diverse appearance of the same vehicle. We propose the adaptive feature learning technique based on the space-time prior to address these issues. The idea is demonstrated effectively in both the human Re-ID and the vehicle Re-ID tasks. We train a vehicle feature extractor in a multi-task learning manner on three existing vehicle datasets and fine-tune the feature extractor with the adaptive feature learning technique on the target domain. We then develop a vehicle Re-ID system based on the learned vehicle feature extractor. Finally, our meticulous system design leads to the second place in the 2018 NVIDIA AI City Challenge Track 3.","tags":["vehicle re-identification","space-time prior"],"title":"Vehicle Re-identification with the Space-Time Prior","type":"publication"},{"authors":["**chih-ting liu**","yi-heng wu","yu-sheng lin","shao-yi chien"],"categories":["pruning"],"content":"","date":1527379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527379200,"objectID":"034b5d4e5abbb9d215442b962cbe3486","permalink":"https://jackie840129.github.io/publication/iscas18_cpo/","publishdate":"2020-08-24T00:00:00Z","relpermalink":"/publication/iscas18_cpo/","section":"publication","summary":"Deep Convolutional Neural Networks (CNNs) are widely employed in modern computer vision algorithms, where the input image is convolved iteratively by many kernels to extract the knowledge behind it. However, with the depth of convolutional layers getting deeper and deeper in recent years, the enormous computational complexity makes it difficult to be deployed on embedded systems with limited hardware resources. In this paper, we propose two computation-performance optimization methods to reduce the redundant convolution kernels of a CNN with performance and architecture constraints, and apply it to a network for super resolution (SR). Using PSNR drop compared to the original network as the performance criterion, our method can get the optimal PSNR under a certain computation budget constraint. On the other hand, our method is also capable of minimizing the computation required under a given PSNR drop.","tags":["filter pruning","kernel sparsity","performance-computation trade-off"],"title":"Computation-Performance Optimization of Convolutional Neural Networks with Redundant Kernel Removal","type":"publication"},{"authors":null,"categories":null,"content":"\r[Ph.D. Dissertation] My Ph.D. dissertation \u0026ldquo;Learning Efficient and Effective Person Re-identification in Multi-Camera Tracking System and Beyond\u0026rdquo; can be downloaded here\n[Aug. 2022] I start my new career as an computer vision applied scientist in Amazon Lab126 at Taipei!\n[Jul. 2022] I pass the oral defense and got my Ph.D. degree from National Taiwan University (NTU)!\n[Nov. 2021] Our paper FedFR is accepted by AAAI Conference on Artificial Intelligence 2022!\n","date":1512057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512057600,"objectID":"a0812ae5f3c926fea6faf4472cefc8e2","permalink":"https://jackie840129.github.io/news/","publishdate":"2017-12-01T00:00:00+08:00","relpermalink":"/news/","section":"","summary":"\r\nList of news.\r\n","tags":[],"title":"News","type":"page"}]